---
title: "Measuring Meaning in Mixed Methods - Week 3"
output:
  github_document
---

```{r setup, include=FALSE}
knitr::opts_chunk$set(echo = TRUE)
```


#Structural Topic Modeling, or STM. 

STM is very similar to LDA, but it employs meta data about documents (such as the name of the author or the date in which the document was produced) to improve the assignment of words to latent topics in a corpus.

We import 13246 blog posts 

```{r}
google_doc_id <- "1LcX-JnpGB0lU1iDnXnxB6WFqBywUKpew" # google file ID
poliblogs<-read.csv(sprintf("https://docs.google.com/uc?id=%s&export=download", google_doc_id), stringsAsFactors = FALSE)

```


The `textProcessor` function in STM automatically removes a) punctuation; b) stop words; c) numbers, and d) stems each word.

```{r}
#install.packages("stm")
library(stm)
processed <- textProcessor(poliblogs$documents, metadata = poliblogs)
```

The `stm` package  requires us to store the documents, meta data, and "vocab"---or total list of words described in the documents---in separate objects (see code below). The first line of code eliminates both extremely common terms and extremely rare terms, as is common practice in topic modeling, since such terms make word-topic assignment much more difficult.

```{r}
out <- prepDocuments(processed$documents, processed$vocab, processed$meta)
docs <- out$documents
vocab <- out$vocab
meta <-out$meta
```

Before we run our first model, we have to make another decision about the number of topics we might expect to find in the corpus. Let's start out with 10. 
We also need to specify how we want to use the meta data. This model uses both the "rating" variable (that describes whether the blog is liberal or conservative) as well as the day or date variable to improve topic classification.

```{r}
First_STM <- stm(documents = out$documents, vocab = out$vocab,
                 K = 10, prevalence =~ rating + s(day) ,
                 max.em.its = 75, data = out$meta,
                 init.type = "Spectral", verbose = FALSE)

```

inspect our results by browsing the top words associated with each topic

```{r}
plot(First_STM)
```

The `stm` package has another useful function called `findThoughts` which extracts passages from documents within the corpus that load high on topics specified by the user.

```{r}
findThoughts(First_STM, texts = poliblogs$documents,
             n = 1, topics = 3)
```

The `stm` package has a useful function called `searchK` which allows the user to specify a range of values for `k`, runs STM models for each value of 'k', and then outputs multiple goodness-of-fit measures that are very useful in identifying a range of values of `k` that provide the best fit for the data. The syntax of this function is very similar to the `stm` function, except that the user specifies a range for `k` as one of the arguments. In the code below, we search all values of `k` between 7 and 10.

```{r}
findingk <- searchK(out$documents, out$vocab, K = c(7:10),
                    prevalence =~ rating + s(day), data = meta, verbose=FALSE)
plot(findingk)
```

One of the principal advantages of STM is that one can examine the relationship between topics and various covariates of interest. 
Here we use the `estimateEffect` function to examine the relationship between the liberal/conservative `rating` variable and the first 10 topics, as well as time (`day`).

```{r}
predict_topics<-estimateEffect(formula = 1:10 ~ rating + s(day), stmobj = First_STM, metadata = out$meta, uncertainty = "Global")
```

Once we have the model, we can plot the relationships. The code below picks three topics and plots them according to their association with the liberal/conservative `rating` variable.

```{r}
plot(predict_topics, covariate = "rating", topics = c(3, 5, 9),
     model = First_STM, method = "difference",
     cov.value1 = "Liberal", cov.value2 = "Conservative",
     xlab = "More Conservative ... More Liberal",
     main = "Effect of Liberal vs. Conservative",
     xlim = c(-.1, .1), labeltype = "custom",
     custom.labels = c('Topic 3', 'Topic 5','Topic 9'))

```

We can also plot change in the prevalence of topic over time. The code below plots change in the prevalence of topic 3.

```{r}
plot(predict_topics, "day", method = "continuous", topics = 3,
     model = z, printlegend = FALSE, xaxt = "n", xlab = "Time (2008)")
monthseq <- seq(from = as.Date("2008-01-01"),
                to = as.Date("2008-12-01"), by = "month")
monthnames <- months(monthseq)
axis(1,at = as.numeric(monthseq) - min(as.numeric(monthseq)),
     labels = monthnames)
```
